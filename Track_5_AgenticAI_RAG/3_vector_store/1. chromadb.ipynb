{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "486928bb",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "\n",
    "Introduction\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large language models with external knowledge retrieval. This notebook will walk you through building a complete RAG system using:\n",
    "\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50ae248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from typing import List\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee19f83c",
   "metadata": {},
   "source": [
    "### 1. sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e73880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_docs = [\n",
    "    \"\"\"\n",
    "    Machine Learning Fundamentals\n",
    "\n",
    "    Machine learning is a subset of artificial intelligence that enables\n",
    "    systems to learn and improve from experience without being explicitly\n",
    "    programmed. There are three main types of machine learning: supervised\n",
    "    learning, unsupervised learning, and reinforcement learning. Supervised\n",
    "    learning uses labeled data to train models, while unsupervised learning\n",
    "    finds patterns in unlabeled data. Reinforcement learning learns through\n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "\n",
    "    Deep learning is a subset of machine learning based on artificial neural\n",
    "    networks. These networks are inspired by the human brain and consist of\n",
    "    layers of interconnected nodes. Deep learning has revolutionized fields\n",
    "    like computer vision, natural language processing, and speech recognition.\n",
    "    Convolutional Neural Networks (CNNs) are particularly effective for image\n",
    "    processing, while Recurrent Neural Networks (RNNs) and Transformers excel\n",
    "    at sequential data processing.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"\n",
    "    Natural Language Processing (NLP)\n",
    "\n",
    "    NLP is a field of AI that focuses on the interaction between computers and\n",
    "    human language. Key tasks in NLP include text classification, named entity\n",
    "    recognition, sentiment analysis, machine translation, and question answering.\n",
    "    Modern NLP heavily relies on transformer architectures like BERT, GPT, and T5.\n",
    "    These models use attention mechanisms to understand context and relationships\n",
    "    between words in text.\n",
    "    \"\"\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0068616",
   "metadata": {},
   "source": [
    "save the sample docs in txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2aa7b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sample docs created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "path = Path(\"data\")\n",
    "path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    (path / f\"doc_{i}.txt\").write_text(doc, encoding=\"utf-8\")\n",
    "\n",
    "print(\"✅ Sample docs created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c336e005",
   "metadata": {},
   "source": [
    "### 2. document load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3a134bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='\\n    Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables\\n    systems to learn and improve from experience without being explicitly\\n    programmed. There are three main types of machine learning: supervised\\n    learning, unsupervised learning, and reinforcement learning. Supervised\\n    learning uses labeled data to train models, while unsupervised learning\\n    finds patterns in unlabeled data. Reinforcement learning learns through\\n    interaction with an environment using rewards and penalties.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural\\n    networks. These networks are inspired by the human brain and consist of\\n    layers of interconnected nodes. Deep learning has revolutionized fields\\n    like computer vision, natural language processing, and speech recognition.\\n    Convolutional Neural Networks (CNNs) are particularly effective for image\\n    processing, while Recurrent Neural Networks (RNNs) and Transformers excel\\n    at sequential data processing.\\n    '),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='\\n    Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and\\n    human language. Key tasks in NLP include text classification, named entity\\n    recognition, sentiment analysis, machine translation, and question answering.\\n    Modern NLP heavily relies on transformer architectures like BERT, GPT, and T5.\\n    These models use attention mechanisms to understand context and relationships\\n    between words in text.\\n    ')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DirectoryLoader(\n",
    "    path,\n",
    "    glob='*.txt',\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding': 'utf-8'}\n",
    ")\n",
    "\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a69c73",
   "metadata": {},
   "source": [
    "### 3. Splitting docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b00bd88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total docs after split: 9\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables\\n    systems to learn and improve from experience without being explicitly\\n    programmed. There are three main types of machine learning: supervised\\n    learning, unsupervised learning, and reinforcement learning. Supervised'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='learning uses labeled data to train models, while unsupervised learning\\n    finds patterns in unlabeled data. Reinforcement learning learns through\\n    interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural\\n    networks. These networks are inspired by the human brain and consist of\\n    layers of interconnected nodes. Deep learning has revolutionized fields'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='like computer vision, natural language processing, and speech recognition.\\n    Convolutional Neural Networks (CNNs) are particularly effective for image\\n    processing, while Recurrent Neural Networks (RNNs) and Transformers excel\\n    at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='NLP is a field of AI that focuses on the interaction between computers and\\n    human language. Key tasks in NLP include text classification, named entity\\n    recognition, sentiment analysis, machine translation, and question answering.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Modern NLP heavily relies on transformer architectures like BERT, GPT, and T5.\\n    These models use attention mechanisms to understand context and relationships\\n    between words in text.')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=30,\n",
    "    length_function=len,\n",
    "    separators=['\\n\\n', '\\n', '. ', '']\n",
    ")\n",
    "\n",
    "splitted_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"total docs after split: {len(splitted_docs)}\\n\")\n",
    "splitted_docs\n",
    "# for i, v in enumerate(splitted_docs):\n",
    "#     print(f\"chunk {i}\\n {splitted_docs[i].page_content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373df741",
   "metadata": {},
   "source": [
    "### 4. Create Embedding and store in Vector store ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "def854b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector store created with '9' vectors\n",
      "location: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=splitted_docs,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name='rag_collection'\n",
    ")\n",
    "\n",
    "print(f\"vector store created with '{vector_store._collection.count()}' vectors\")\n",
    "print(f'location: {persist_directory}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc0251",
   "metadata": {},
   "source": [
    "### 5. Test Similarity Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c526c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables\\n    systems to learn and improve from experience without being explicitly\\n    programmed. There are three main types of machine learning: supervised\\n    learning, unsupervised learning, and reinforcement learning. Supervised'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what are the types of machine learning\"\n",
    "\n",
    "similar_docs = vector_store.similarity_search(query, k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae0a0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='NLP is a field of AI that focuses on the interaction between computers and\\n    human language. Key tasks in NLP include text classification, named entity\\n    recognition, sentiment analysis, machine translation, and question answering.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Modern NLP heavily relies on transformer architectures like BERT, GPT, and T5.\\n    These models use attention mechanisms to understand context and relationships\\n    between words in text.'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is NLP?\"\n",
    "similar_docs = vector_store.similarity_search(query, k=5)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4cbada94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural\\n    networks. These networks are inspired by the human brain and consist of\\n    layers of interconnected nodes. Deep learning has revolutionized fields'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'what is deep learning?'\n",
    "similar_docs = vector_store.similarity_search(query, k=3)\n",
    "similar_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea191f37",
   "metadata": {},
   "source": [
    "#### Advanced Similarity Search with Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8121b32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       "  0.2128422111272812),\n",
       " (Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural\\n    networks. These networks are inspired by the human brain and consist of\\n    layers of interconnected nodes. Deep learning has revolutionized fields'),\n",
       "  0.22426888346672058),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       "  0.30851638317108154)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.similarity_search_with_score(query, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc247a1",
   "metadata": {},
   "source": [
    "### Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. \n",
    "The scoring depends on the distance metric used:\n",
    "\n",
    "**ChromaDB default: Uses L2 distance (Euclidean distance)**\n",
    "- Lower scores = MORE similar (closer in vector space)  \n",
    "- Score of 0 = identical vectors  \n",
    "- Typical range: 0 to 2 (but can be higher)  \n",
    "\n",
    "**Cosine similarity (if configured):**\n",
    "- Higher scores = MORE similar  \n",
    "- Range: -1 to 1 (1 being identical)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc28d5c",
   "metadata": {},
   "source": [
    "### 6. Initialize LLM, RAG Chain, Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa0b9608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"LLM can refer to a few different things depending on the context:\\n\\n1. **Master of Laws (LL.M.)**: This is an advanced, postgraduate academic degree in law. It is typically pursued by individuals who already hold a first degree in law and wish to specialize further in a particular area or gain international legal qualifications.\\n\\n2. **Large Language Model**: In the context of artificial intelligence and machine learning, LLM refers to large-scale language models like OpenAI's GPT-3, GPT-4, or similar models developed by other organizations. These models are trained on vast amounts of text data and are capable of understanding and generating human-like text, making them useful for a variety of applications such as chatbots, translations, and more.\\n\\n3. **Logical Link Management**: In telecommunications, LLM can refer to Logical Link Management, which is part of the control functions of a data link that ensures reliable transmission.\\n\\nIf you have a specific context in mind, please let me know, and I can provide more tailored information!\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model='gpt-4o',\n",
    ")\n",
    "\n",
    "llm.predict(\"What is LLM?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d942ed",
   "metadata": {},
   "source": [
    "### Modern RAG Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c5b5bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000211BE029110>, search_kwargs={})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "# create retriver\n",
    "retriever = vector_store.as_retriever(search_kwarg={\"k\": 3})\n",
    "\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73ea990e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a prompt template\n",
    "system_prompt = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', system_prompt),\n",
    "    ('human', \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "707b79cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef7a5ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211BE753310>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211BE750CD0>, root_client=<openai.OpenAI object at 0x00000211BE7521D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000211BE56F750>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_chain = create_stuff_documents_chain(llm=llm, prompt=prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d68eb5e",
   "metadata": {},
   "source": [
    "This chain:\n",
    "- Takes retrieved documents\n",
    "- \"Stuffs\" them into the prompt's {context} placeholder\n",
    "- Sends the complete prompt to the LLM\n",
    "- Returns the LLM's response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5d3e77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000211BE029110>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211BE753310>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211BE750CD0>, root_client=<openai.OpenAI object at 0x00000211BE7521D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000211BE56F750>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "386fd9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is artificial intelligence?\"\n",
    "\n",
    "result = rag_chain.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1471cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence (AI) is a branch of computer science that involves creating systems capable of performing tasks that typically require human intelligence. These tasks include reasoning, learning, problem-solving, perception, and language understanding. AI encompasses various subfields, including machine learning and natural language processing.\n"
     ]
    }
   ],
   "source": [
    "print(result['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9b398e",
   "metadata": {},
   "source": [
    "### Alternate method to create the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0be22d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000211BE029110>, search_kwargs={}),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='\\n                                                 Use the following context to answer the question. If you do not know the answer based on the context, say you do not know.\\n                                                 Provide specific details from the context to support your answer.\\n\\n                                                 Context:\\n                                                 {context}\\n\\n                                                 Question:\\n                                                 {question}\\n\\n                                                 Answer:'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211BE753310>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211BE750CD0>, root_client=<openai.OpenAI object at 0x00000211BE7521D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000211BE56F750>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "                                                 Use the following context to answer the question. If you do not know the answer based on the context, say you do not know.\n",
    "                                                 Provide specific details from the context to support your answer.\n",
    "\n",
    "                                                 Context:\n",
    "                                                 {context}\n",
    "\n",
    "                                                 Question:\n",
    "                                                 {question}\n",
    "\n",
    "                                                 Answer:\"\"\")\n",
    "\n",
    "\n",
    "def format_doc(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain_adv = ({\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "                 | custom_prompt\n",
    "                 | llm\n",
    "                 | StrOutputParser())\n",
    "\n",
    "rag_chain_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc28e749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context does not provide a specific definition of AI. However, it mentions that machine learning is a subset of artificial intelligence that allows systems to learn and improve from experience without being explicitly programmed.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_adv.invoke(\"What is AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b846647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='NLP is a field of AI that focuses on the interaction between computers and\\n    human language. Key tasks in NLP include text classification, named entity\\n    recognition, sentiment analysis, machine translation, and question answering.'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables\\n    systems to learn and improve from experience without being explicitly\\n    programmed. There are three main types of machine learning: supervised\\n    learning, unsupervised learning, and reinforcement learning. Supervised'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what is AI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c196cf",
   "metadata": {},
   "source": [
    "### Add new docs in existing vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a97f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'manual', 'topic': 'reinforcement learning'}, page_content='\\nReinforcement Learning in Detail\\n\\nReinforcement learning (RL) is a type of machine learning where an agent learns to make\\ndecisions by interacting with an environment. The agent receives rewards or penalties\\nbased on its actions and learns to maximize cumulative reward over time. Key concepts\\nin RL include: states, actions, rewards, policies, and value functions. Popular RL\\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and\\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo),\\nrobotics, and autonomous systems.\\n')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add new documents to the existing vector store\n",
    "new_txt = \"\"\"\n",
    "Reinforcement Learning in Detail\n",
    "\n",
    "Reinforcement learning (RL) is a type of machine learning where an agent learns to make\n",
    "decisions by interacting with an environment. The agent receives rewards or penalties\n",
    "based on its actions and learns to maximize cumulative reward over time. Key concepts\n",
    "in RL include: states, actions, rewards, policies, and value functions. Popular RL\n",
    "algorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and\n",
    "Actor-Critic methods. RL has been successfully applied to game playing (like AlphaGo),\n",
    "robotics, and autonomous systems.\n",
    "\"\"\"\n",
    "\n",
    "new_doc = Document(page_content=new_txt, \n",
    "                   metadata={\"source\": \"manual\", \"topic\": \"reinforcement learning\"}\n",
    "                   )\n",
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b3e2a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_splitter = RecursiveCharacterTextSplitter(chunk_size=300, \n",
    "                                              chunk_overlap=30, \n",
    "                                              separators=[\"\\n\\n\", \"\\n\", \" \", \".\"], \n",
    "                                              length_function=len)\n",
    "new_doc_chunk = txt_splitter.split_documents([new_doc])\n",
    "len(new_doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9866ee0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'manual', 'topic': 'reinforcement learning'}, page_content='Reinforcement Learning in Detail'),\n",
       " Document(metadata={'source': 'manual', 'topic': 'reinforcement learning'}, page_content='Reinforcement learning (RL) is a type of machine learning where an agent learns to make\\ndecisions by interacting with an environment. The agent receives rewards or penalties\\nbased on its actions and learns to maximize cumulative reward over time. Key concepts'),\n",
       " Document(metadata={'source': 'manual', 'topic': 'reinforcement learning'}, page_content='in RL include: states, actions, rewards, policies, and value functions. Popular RL\\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and\\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo),\\nrobotics, and autonomous systems.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "773db346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['840beff1-8dd1-49bf-bad3-80bf67c5fa5d',\n",
       " '8d76a685-a835-4625-b6d6-7aa34d8ae210',\n",
       " '00949937-369d-4898-91d9-6da0552c7508']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(new_doc_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fccf4c16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives rewards or penalties based on its actions and learns to maximize cumulative reward over time. Key concepts in RL include states, actions, rewards, policies, and value functions. Popular RL algorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and Actor-Critic methods. RL has been successfully applied to game playing (like AlphaGo), robotics, and autonomous systems.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_adv.invoke(\"what is reinforcement learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1eff2428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'topic': 'reinforcement learning', 'source': 'manual'}, page_content='Reinforcement learning (RL) is a type of machine learning where an agent learns to make\\ndecisions by interacting with an environment. The agent receives rewards or penalties\\nbased on its actions and learns to maximize cumulative reward over time. Key concepts'),\n",
       " Document(metadata={'source': 'manual', 'topic': 'reinforcement learning'}, page_content='Reinforcement Learning in Detail'),\n",
       " Document(metadata={'topic': 'reinforcement learning', 'source': 'manual'}, page_content='in RL include: states, actions, rewards, policies, and value functions. Popular RL\\nalgorithms include Q-learning, Deep Q-Networks (DQN), Policy Gradient methods, and\\nActor-Critic methods. RL has been successfully applied to game playing (like AlphaGo),\\nrobotics, and autonomous systems.'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what is reinforcement learning?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900960d7",
   "metadata": {},
   "source": [
    "### Conversational Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "61925fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000021184787A60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question which might reference context \\nin the chat history, formulate a standalone question which can be understood without the chat history. Do not answer \\nthe question, just formulate it if needed and otherwise return it as is.\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question which might reference context \n",
    "in the chat history, formulate a standalone question which can be understood without the chat history. Do not answer \n",
    "the question, just formulate it if needed and otherwise return it as is.\n",
    "\"\"\"\n",
    "\n",
    "contextualize_q_system_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "contextualize_q_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8898638b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000211BE029110>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000021184787A60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question which might reference context \\nin the chat history, formulate a standalone question which can be understood without the chat history. Do not answer \\nthe question, just formulate it if needed and otherwise return it as is.\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211BE753310>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211BE750CD0>, root_client=<openai.OpenAI object at 0x00000211BE7521D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000211BE56F750>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000211BE029110>, search_kwargs={})), kwargs={}, config={'run_name': 'chat_retriever_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_system_prompt\n",
    ")\n",
    "history_aware_retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebf628fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000021184787A60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context\\nto answer the question. If you do not know the answer, just say 'I don't know'. Use three sentences maximum and keep \\nthe answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211BE753310>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211BE750CD0>, root_client=<openai.OpenAI object at 0x00000211BE7521D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000211BE56F750>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context\n",
    "to answer the question. If you do not know the answer, just say 'I don't know'. Use three sentences maximum and keep \n",
    "the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    ('system', qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "qa_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "079c46ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000211BE029110>, search_kwargs={}))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000021184787A60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Given a chat history and the latest user question which might reference context \\nin the chat history, formulate a standalone question which can be understood without the chat history. Do not answer \\nthe question, just formulate it if needed and otherwise return it as is.\\n'), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "           | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211BE753310>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211BE750CD0>, root_client=<openai.OpenAI object at 0x00000211BE7521D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000211BE56F750>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "           | StrOutputParser()\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x00000211BE029110>, search_kwargs={})), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x0000021184787A60>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context\\nto answer the question. If you do not know the answer, just say 'I don't know'. Use three sentences maximum and keep \\nthe answer concise.\\n\\nContext: {context}\"), additional_kwargs={}), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000211BE753310>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000211BE750CD0>, root_client=<openai.OpenAI object at 0x00000211BE7521D0>, root_async_client=<openai.AsyncOpenAI object at 0x00000211BE56F750>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_rag = create_retrieval_chain(history_aware_retriever, qa_chain)\n",
    "conversational_rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ee5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: what is machine learning?\n",
      "A: Machine learning is a subset of artificial intelligence that enables systems to learn and improve from experience without being explicitly programmed.\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "\n",
    "result1 = conversational_rag.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"what is machine learning?\"\n",
    "})\n",
    "\n",
    "print(\"Q: what is machine learning?\")\n",
    "print(f\"A: {result1['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "27cb26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend([\n",
    "    HumanMessage(content=\"What is machine learning?\"),\n",
    "    AIMessage(content=result1['answer'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e96d1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What are it's main types?\n",
      "A: The main types of machine learning are supervised learning, unsupervised learning, and reinforcement learning.\n"
     ]
    }
   ],
   "source": [
    "result2 = conversational_rag.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"What are it's main types?\"\n",
    "})\n",
    "\n",
    "print(\"Q: What are it's main types?\")\n",
    "print(f\"A: {result2['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a57733",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend([\n",
    "    HumanMessage(content=\"What are it's main types\"),\n",
    "    AIMessage(content=result2['answer'])\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
